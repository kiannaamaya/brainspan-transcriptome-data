{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AHmD9fJx3th"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from scipy.special import softmax\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij0s4CBGykiR"
      },
      "source": [
        "## Simple Average-Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmeMiZO0ykG4"
      },
      "outputs": [],
      "source": [
        "# model files for both datasets\n",
        "rnaseq_model = joblib.load('baseline_model_outputs/rnaseq/XGBClassifier/trained_model.pkl')\n",
        "microRNA_model = joblib.load('baseline_model_outputs/microRNA/XGBClassifier/trained_model.pkl')\n",
        "\n",
        "# data files for the first dataset (RNA seq)\n",
        "X_train_RNAseq = joblib.load('baseline_model_outputs/rnaseq/X_train.pkl')\n",
        "X_test_RNAseq = joblib.load('baseline_model_outputs/rnaseq/X_test.pkl')\n",
        "y_train_RNAseq = joblib.load('baseline_model_outputs/rnaseq/y_train.pkl')\n",
        "y_test_RNAseq = joblib.load('baseline_model_outputs/rnaseq/y_test.pkl')\n",
        "\n",
        "# data files for the second dataset (microRNA)\n",
        "X_train_microRNA = joblib.load('baseline_model_outputs/microRNA/X_train.pkl')\n",
        "X_test_microRNA = joblib.load('baseline_model_outputs/microRNA/X_test.pkl')\n",
        "y_train_microRNA = joblib.load('baseline_model_outputs/microRNA/y_train.pkl')\n",
        "y_test_microRNA = joblib.load('baseline_model_outputs/microRNA/y_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction with probabilities for microRNA data\n",
        "xgb_probs_microRNA = microRNA_model.predict_proba(X_test_microRNA)\n",
        "\n",
        "# prediction with probabilities for RNAseq data\n",
        "xgb_probs_RNAseq = rnaseq_model.predict_proba(X_test_RNAseq)\n",
        "\n",
        "# when only using the XGB probabilities, there's no averaging needed\n",
        "avg_probs_microRNA = xgb_probs_microRNA\n",
        "avg_probs_RNAseq = xgb_probs_RNAseq\n",
        "\n",
        "# getting the predicted class\n",
        "avg_predictions_microRNA = np.argmax(avg_probs_microRNA, axis=1)\n",
        "avg_predictions_RNAseq = np.argmax(avg_probs_RNAseq, axis=1)\n",
        "\n",
        "# evaluating the performance for each dataset\n",
        "accuracy_microRNA = accuracy_score(y_test_microRNA, avg_predictions_microRNA)\n",
        "f1_microRNA = f1_score(y_test_microRNA, avg_predictions_microRNA, average='macro')\n",
        "accuracy_RNAseq = accuracy_score(y_test_RNAseq, avg_predictions_RNAseq)\n",
        "f1_RNAseq = f1_score(y_test_RNAseq, avg_predictions_RNAseq, average='macro')\n",
        "\n",
        "print(\"Micro RNA Accuracy:\", accuracy_microRNA)\n",
        "print(\"Micro RNA Macro F1-score:\", f1_microRNA)\n",
        "print(\"RNAseq Accuracy:\", accuracy_RNAseq)\n",
        "print(\"RNAseq Macro F1-score:\", f1_RNAseq)"
      ],
      "metadata": {
        "id": "g5136rkYDjSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3abed3-21ac-477e-99b3-66cbd4b4ef87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro RNA Accuracy: 0.8863636363636364\n",
            "Micro RNA Macro F1-score: 0.8873285663022834\n",
            "RNAseq Accuracy: 0.9913793103448276\n",
            "RNAseq Macro F1-score: 0.9846808510638297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvcKpJjyndt"
      },
      "source": [
        "## Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_RNAseq = rnaseq_model.predict(X_test_RNAseq)\n",
        "preds_microRNA = microRNA_model.predict(X_test_microRNA)\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for i in range(max(len(preds_RNAseq), len(preds_microRNA))):\n",
        "    if i < len(preds_RNAseq) and i < len(preds_microRNA):\n",
        "        pred1 = preds_RNAseq[i]\n",
        "        pred2 = preds_microRNA[i]\n",
        "\n",
        "        if pred1 == pred2:\n",
        "            final_predictions.append(pred1)\n",
        "        else:\n",
        "            final_predictions.append(pred1)\n",
        "    elif i < len(preds_RNAseq):\n",
        "        final_predictions.append(preds_RNAseq[i])\n",
        "    else:\n",
        "        final_predictions.append(preds_microRNA[i])\n",
        "\n",
        "final_predictions = np.array(final_predictions)\n",
        "\n",
        "y_test_combined = y_test_RNAseq if len(y_test_RNAseq) == len(final_predictions) else y_test_microRNA\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, final_predictions)\n",
        "f1 = f1_score(y_test_combined, final_predictions, average='macro')\n",
        "\n",
        "print(\"Majority Voting Accuracy:\", accuracy)\n",
        "print(\"Majority Voting Macro F1-score:\", f1)\n"
      ],
      "metadata": {
        "id": "1dWON8XhESB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb63398-862a-4362-9cb4-468c83a9962c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority Voting Accuracy: 0.9913793103448276\n",
            "Majority Voting Macro F1-score: 0.9846808510638297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rank Fusion"
      ],
      "metadata": {
        "id": "50uXdYqyqfZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs_RNAseq = rnaseq_model.predict_proba(X_test_RNAseq)\n",
        "probs_microRNA = microRNA_model.predict_proba(X_test_microRNA)\n",
        "\n",
        "# convert probabilities to ranks for each sample\n",
        "ranks_RNAseq = probs_RNAseq.argsort().argsort()   # a way to obtain ranks from probabilities\n",
        "ranks_microRNA = probs_microRNA.argsort().argsort()\n",
        "\n",
        "avg_ranks = []\n",
        "\n",
        "# only average for the minimum of the two lengths to avoid out-of-index errors\n",
        "for i in range(min(len(ranks_RNAseq), len(ranks_microRNA))):\n",
        "    avg_rank = (ranks_RNAseq[i] + ranks_microRNA[i]) / 2.0\n",
        "    avg_ranks.append(avg_rank)\n",
        "\n",
        "avg_ranks = np.array(avg_ranks)\n",
        "\n",
        "# choose the class with the highest average rank as the final prediction\n",
        "final_predictions_rank_fusion = np.argmax(avg_ranks, axis=1)\n",
        "\n",
        "y_test_combined = y_test_RNAseq[:len(final_predictions_rank_fusion)]\n",
        "\n",
        "accuracy_rank_fusion = accuracy_score(y_test_combined, final_predictions_rank_fusion)\n",
        "f1_rank_fusion = f1_score(y_test_combined, final_predictions_rank_fusion, average='macro')\n",
        "\n",
        "print(\"Rank Fusion Accuracy:\", accuracy_rank_fusion)\n",
        "print(\"Rank Fusion Macro F1-score:\", f1_rank_fusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qn54SrKqlSy",
        "outputId": "ce48b473-0eb2-46c9-af4b-04abf2dce2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank Fusion Accuracy: 0.5681818181818182\n",
            "Rank Fusion Macro F1-score: 0.539533584694875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meta-Classifier Fusion"
      ],
      "metadata": {
        "id": "hOJRjqTxq_nU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Phase"
      ],
      "metadata": {
        "id": "H8AHUJBjrEwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_probs_RNAseq = rnaseq_model.predict_proba(X_train_RNAseq)\n",
        "train_probs_microRNA = microRNA_model.predict_proba(X_train_microRNA)\n",
        "\n",
        "min_length = min(len(train_probs_RNAseq), len(train_probs_microRNA))\n",
        "\n",
        "train_probs_RNAseq = train_probs_RNAseq[:min_length]\n",
        "train_probs_microRNA = train_probs_microRNA[:min_length]\n",
        "\n",
        "# use the probabilities as features for the meta-classifier\n",
        "X_train_meta = np.hstack((train_probs_RNAseq, train_probs_microRNA))\n",
        "y_train_meta = y_train_RNAseq[:min_length]\n",
        "meta_classifier = RandomForestClassifier()\n",
        "meta_classifier.fit(X_train_meta, y_train_meta)\n"
      ],
      "metadata": {
        "id": "knwbUSzDrDpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Phase"
      ],
      "metadata": {
        "id": "n-luwBOJrJT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs_RNAseq = rnaseq_model.predict_proba(X_test_RNAseq)\n",
        "test_probs_microRNA = microRNA_model.predict_proba(X_test_microRNA)\n",
        "\n",
        "min_length_test = min(len(test_probs_RNAseq), len(test_probs_microRNA))\n",
        "\n",
        "test_probs_RNAseq = test_probs_RNAseq[:min_length_test]\n",
        "test_probs_microRNA = test_probs_microRNA[:min_length_test]\n",
        "\n",
        "# use the probabilities as features for the meta-classifier\n",
        "X_test_meta = np.hstack((test_probs_RNAseq, test_probs_microRNA))\n",
        "\n",
        "final_predictions_meta = meta_classifier.predict(X_test_meta)\n",
        "\n",
        "y_test_combined = y_test_RNAseq[:min_length_test]\n",
        "\n",
        "accuracy_meta = accuracy_score(y_test_combined, final_predictions_meta)\n",
        "f1_meta = f1_score(y_test_combined, final_predictions_meta, average='macro')\n",
        "\n",
        "print(\"Meta-classifier Fusion Accuracy:\", accuracy_meta)\n",
        "print(\"Meta-classifier Fusion Macro F1-score:\", f1_meta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gEbqGu2rJGH",
        "outputId": "dcdeaa5f-3fe6-443a-a126-9739995754db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-classifier Fusion Accuracy: 1.0\n",
            "Meta-classifier Fusion Macro F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some improvements should be made soon. I have look over what I have done again."
      ],
      "metadata": {
        "id": "MEUZioBfrq9Y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}