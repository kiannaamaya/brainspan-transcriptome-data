{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjnh_d5vK1_K",
        "outputId": "80ea029f-3566-4599-d2d9-d7a11656bfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "print(joblib.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnNxS2KyLPiT",
        "outputId": "f6d352b8-c437-4853-fbdc-c5c6b5a1c76f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_ages(age):\n",
        "    if pd.isnull(age) or not isinstance(age, (str, float, int)):\n",
        "        return 'Unknown'\n",
        "    age_str = str(age)\n",
        "\n",
        "    if 'pcw' in age_str:\n",
        "        weeks = int(age_str.split(' ')[0])\n",
        "        if weeks >= 4 and weeks <= 7: # 4-7 pcw\n",
        "            return 'Embryonic'\n",
        "        elif weeks >= 8 and weeks <= 38: # 8-38 pcw\n",
        "            return 'Prenatal'\n",
        "    elif 'mos' in age_str or 'M' in age_str:\n",
        "        months = int(age_str.split(' ')[0])\n",
        "        if months >= 0 and months <= 19: # 0-19 months\n",
        "            return 'Infancy'\n",
        "    elif 'yrs' in age_str or 'Y' in age_str:\n",
        "        years = int(age_str.split(' ')[0])\n",
        "        if years >= 1 and years <= 11: # 1-11 years\n",
        "            return 'Childhood'\n",
        "        elif years >= 12 and years <= 19: # 12-19 years\n",
        "            return 'Adolescence'\n",
        "        elif years >= 20: # 20 years and above\n",
        "            return 'Adulthood'\n",
        "\n",
        "    # return 'Unknown' for any other cases\n",
        "    return 'Unknown'"
      ],
      "metadata": {
        "id": "MgsCTqsKLUhE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(data, lower_bound=1, upper_bound=255):\n",
        "    # apply threshold to filter out very low values\n",
        "    threshold = data.mean().mean()\n",
        "    data[data < threshold] = 0\n",
        "\n",
        "    # scale the data\n",
        "    max_abs_value = data.abs().max().max()\n",
        "    data_scaled = data.apply(lambda x: ((x / max_abs_value) * (upper_bound - lower_bound)) + lower_bound if x.max() != 0 else x, axis=1)\n",
        "    return data_scaled"
      ],
      "metadata": {
        "id": "l1w9ZPwELX7Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_image(dataframe, image_size=150):\n",
        "    total_size = image_size * image_size\n",
        "    image_array = np.zeros((len(dataframe), total_size))\n",
        "\n",
        "    for i, row in enumerate(dataframe.to_numpy()):\n",
        "        image_array[i, :len(row)] = row[:total_size]\n",
        "\n",
        "    # reshape to have it in 2D image format (num_samples, image_width, image_height)\n",
        "    image_array = image_array.reshape(-1, image_size, image_size)\n",
        "\n",
        "    return image_array"
      ],
      "metadata": {
        "id": "R1xRxAs3Lcw0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data_path, file_type='csv'):\n",
        "    \"\"\"\n",
        "    Preprocess the data and return the train-test split.\n",
        "\n",
        "    Args:\n",
        "    - data_path (str): Path to the data file.\n",
        "    - file_type (str): File format ('csv', 'excel', 'txt').\n",
        "\n",
        "    Returns:\n",
        "    - X_train, X_test, y_train, y_test: Train-test split of the preprocessed data.\n",
        "    \"\"\"\n",
        "    subset_rows = 20\n",
        "\n",
        "\n",
        "    if 'methylation' in data_path.lower() and file_type == 'csv':\n",
        "        chunk_size = 5\n",
        "        chunks = pd.read_csv(data_path, chunksize=chunk_size)\n",
        "\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "        for chunk in chunks:\n",
        "            chunk = chunk.head(subset_rows)\n",
        "            X_chunk, y_chunk = preprocess_chunk(chunk, 'Methylation')\n",
        "\n",
        "            X_list.append(X_chunk)\n",
        "            y_list.append(y_chunk)\n",
        "\n",
        "        X_data = pd.concat(X_list, axis=0)\n",
        "        y_data = pd.concat(y_list, axis=0)\n",
        "\n",
        "        data = pd.concat([X_data, y_data], axis=1)\n",
        "        print(\"Columns after processing all chunks:\", data.columns)\n",
        "\n",
        "    else:\n",
        "        if file_type == 'csv':\n",
        "            data = pd.read_csv(data_path, index_col=0)\n",
        "        elif file_type == 'excel':\n",
        "            data = pd.read_excel(data_path, index_col=0)\n",
        "        elif file_type == 'txt':\n",
        "            data = pd.read_csv(data_path, sep='\\t', index_col=0)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file type\")\n",
        "        print(\"Columns after determining data type:\", data.columns)\n",
        "\n",
        "    if 'rnaseq' in data_path.lower():\n",
        "        data_type = 'RNA-Seq'\n",
        "    elif 'methylation' in data_path.lower():\n",
        "        data_type = 'Methylation'\n",
        "    elif 'microrna' in data_path.lower():\n",
        "        data_type = 'MicroRNA'\n",
        "    else:\n",
        "        raise ValueError(\"Unknown data type\")\n",
        "\n",
        "    print(data.columns)\n",
        "\n",
        "    data['age_group'] = data['age'].apply(bin_ages)\n",
        "\n",
        "    if data_type == 'RNA-Seq':\n",
        "        label_map = {'Prenatal': 0, 'Infancy': 0, 'Childhood': 1, 'Adolescence': 2, 'Adulthood': 3}\n",
        "    elif data_type == 'MicroRNA':\n",
        "        label_map = {'Infancy': 0, 'Childhood': 1, 'Adolescence': 2, 'Adulthood': 3}\n",
        "    else:\n",
        "        label_map = {'Embryonic': 0, 'Prenatal': 1, 'Infancy': 2, 'Childhood': 3, 'Adolescence': 4, 'Adulthood': 5}\n",
        "\n",
        "    data['age_group'] = data['age_group'].map(label_map)\n",
        "\n",
        "    if data_type == 'RNA-Seq':\n",
        "        data_numeric = data.drop(['age', 'age_group'], axis=1)\n",
        "        one_percent_of_samples = data_numeric.shape[1] * 0.01\n",
        "        mask = data_numeric.gt(1).sum(axis=1) >= one_percent_of_samples\n",
        "        filtered_data = data[mask]\n",
        "        X = filtered_data.drop(['age', 'age_group'], axis=1)\n",
        "        y = filtered_data['age_group']\n",
        "\n",
        "    elif data_type == 'Methylation':\n",
        "        relevant_columns = [col for col in data.columns if col.startswith(('cg', 'rs', 'ch'))] + ['age_group']\n",
        "        filtered_data = data[relevant_columns]\n",
        "        X = filtered_data.drop(['age_group'], axis=1)\n",
        "        y = filtered_data['age_group']\n",
        "\n",
        "    elif data_type == 'MicroRNA':\n",
        "        relevant_columns = [col for col in data.columns if col.startswith('hsa')] + ['age', 'age_group']\n",
        "        filtered_data = data[relevant_columns]\n",
        "        X = filtered_data.drop(['age', 'age_group'], axis=1)\n",
        "        y = filtered_data['age_group']\n",
        "\n",
        "    if y.isnull().any():\n",
        "        print(\"NaNs present in age_group labels!\")\n",
        "        print(data[data['age_group'].isnull()]['age'])\n",
        "\n",
        "    print(np.unique(y))\n",
        "    print(\"About to shuffle\")\n",
        "\n",
        "    X, y = shuffle(X, y, random_state=0)\n",
        "    print(np.unique(y))\n",
        "    # add a small value to avoid log(0)\n",
        "    X_log_scaled = np.log1p(X)  # log1p applies log(1+x) to avoid log(0)\n",
        "    max_log_value = X_log_scaled.max().max()\n",
        "    X_normalized = np.round((X_log_scaled / max_log_value) * 255)\n",
        "    print(X_normalized.iloc[:5, :10])\n",
        "\n",
        "    # split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # convert to images\n",
        "    X_train_images = convert_to_image(X_train)\n",
        "    X_test_images = convert_to_image(X_test)\n",
        "\n",
        "    return X_train_images, X_test_images, y_train, y_test"
      ],
      "metadata": {
        "id": "5g_8aaP4PK2D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data_splits(X_train, X_test, y_train, y_test, output_dir):\n",
        "    \"\"\"\n",
        "    Saves the train-test data splits to the specified directory using joblib.\n",
        "\n",
        "    Args:\n",
        "    - X_train (pd.DataFrame or np.ndarray): Training data features.\n",
        "    - X_test (pd.DataFrame or np.ndarray): Testing data features.\n",
        "    - y_train (pd.Series or np.ndarray): Training data labels.\n",
        "    - y_test (pd.Series or np.ndarray): Testing data labels.\n",
        "    - output_dir (str): Directory path where the data splits will be saved.\n",
        "\n",
        "    Note:\n",
        "    - If the output directory does not exist, it will be created.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    joblib.dump(X_train, os.path.join(output_dir, 'X_train_classifiers.pkl'))\n",
        "    joblib.dump(X_test, os.path.join(output_dir, 'X_test_classifiers.pkl'))\n",
        "    joblib.dump(y_train, os.path.join(output_dir, 'y_train_classifiers.pkl'))\n",
        "    joblib.dump(y_test, os.path.join(output_dir, 'y_test_classifiers.pkl'))"
      ],
      "metadata": {
        "id": "-ZA_RdCdT9UH"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_and_save(images, output_dir, num_images=5, file_name_prefix='default'):\n",
        "    \"\"\"\n",
        "    Plots a specified number of images and saves the plot.\n",
        "\n",
        "    Args:\n",
        "    - images (np.ndarray): Array of images to be plotted.\n",
        "    - num_images (int): Number of images to plot.\n",
        "    - output_dir (str): Directory path where the image plot will be saved.\n",
        "    - file_name_prefix (str): Prefix for the file name of the saved plot.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(20, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        if i < num_images:\n",
        "            ax.imshow(images[i], cmap='magma')\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    file_path = os.path.join(output_dir, f\"{file_name_prefix}_images.png\")\n",
        "    plt.savefig(file_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Images saved to {file_path}\")"
      ],
      "metadata": {
        "id": "O93EqKH0LpRq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Td1YS5QKYEHe"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(y_test, y_prob, output_dir):\n",
        "    \"\"\"\n",
        "    Plots the Receiver Operating Characteristic (ROC) curve for multi-class classification and saves the plot.\n",
        "\n",
        "    Args:\n",
        "    - y_test (pd.Series or np.ndarray): True labels for the test data.\n",
        "    - y_prob (np.ndarray): Probability estimates of the positive class for each class.\n",
        "    - output_dir (str): Directory path where the ROC curve plot will be saved.\n",
        "\n",
        "    Note:\n",
        "    - The function handles multi-class classification by plotting an ROC curve for each class.\n",
        "    - If the provided `output_dir` does not exist, it must be created before calling this function.\n",
        "    \"\"\"\n",
        "    n_classes = len(np.unique(y_test))\n",
        "    mlb = MultiLabelBinarizer(classes=list(range(n_classes)))\n",
        "    y_test_binarized = mlb.fit_transform(y_test.to_numpy().reshape(-1, 1))\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    macro_roc_auc = roc_auc_score(y_test_binarized, y_prob, average='macro')\n",
        "    for i in range(n_classes):\n",
        "        print(f\"Class {i} ROC AUC: {roc_auc[i]:.2f}\")\n",
        "    print(f\"Macro-average ROC AUC: {macro_roc_auc:.2f}\")\n",
        "\n",
        "    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(os.path.join(output_dir, 'roc_curve.png'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "bXggIdBXUFih"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(data_paths):\n",
        "    \"\"\"\n",
        "    The main pipeline to preprocess data, train CNNs, evaluate their performance, and save the results.\n",
        "    \"\"\"\n",
        "    for data_path in data_paths:\n",
        "        data_type = os.path.basename(data_path).split('_')[0]\n",
        "\n",
        "        X_train, X_test, y_train, y_test = preprocess_data(data_path)\n",
        "        save_data_splits(X_train, X_test, y_train, y_test, os.path.join('baseline_cnn_classifier_outputs', data_type))\n",
        "\n",
        "        X_train_images_expanded = np.expand_dims(X_train, axis=-1)\n",
        "        X_test_images_expanded = np.expand_dims(X_test, axis=-1)\n",
        "        input_shape = X_train_images_expanded.shape[1:]\n",
        "        num_classes = len(np.unique(y_train))\n",
        "\n",
        "        cnn_model = create_cnn(input_shape, num_classes)\n",
        "        cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        history = cnn_model.fit(X_train_images_expanded, y_train, validation_data=(X_test_images_expanded, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "        output_dir = os.path.join('baseline_cnn_classifier_outputs', data_type, 'CNN')\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        cnn_model.save(os.path.join(output_dir, 'trained_cnn_classifier.h5'))\n",
        "\n",
        "        y_prob = cnn_model.predict(X_test_images_expanded)\n",
        "        plot_roc_curve(y_test, y_prob, output_dir)\n",
        "\n",
        "        plot_images_and_save(X_train_images_expanded, output_dir, num_images=3, file_name_prefix='train')\n"
      ],
      "metadata": {
        "id": "lZbGYXtVUHQn"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_paths = [#'methylation_1.csv',\n",
        "              '/content/drive/MyDrive/rnaseq/rnaseq_1.csv',\n",
        "              '/content/drive/MyDrive/microRNA/microRNA_1.csv'\n",
        "              ]\n",
        "main(data_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv0S2E04UJCd",
        "outputId": "f250f822-0037-4197-b1e0-3f8069bcb04f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns after determining data type: Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
            "       ...\n",
            "       '22319', '22320', '22321', '22322', '22323', '22324', '22325', '22326',\n",
            "       '22327', 'age'],\n",
            "      dtype='object', length=22328)\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
            "       ...\n",
            "       '22319', '22320', '22321', '22322', '22323', '22324', '22325', '22326',\n",
            "       '22327', 'age'],\n",
            "      dtype='object', length=22328)\n",
            "[0 1 2 3]\n",
            "About to shuffle\n",
            "[0 1 2 3]\n",
            "                     1    2     3     4     5     6     7     8     9    10\n",
            "donor_id                                                                   \n",
            "H376.XI.50_STC    28.0  1.0  43.0  19.0   9.0  15.0  19.0  49.0  47.0  38.0\n",
            "H376.XI.53_OFC    20.0  2.0  47.0  24.0  10.0  14.0  19.0  39.0  40.0  31.0\n",
            "H376.X.50_CBC     27.0  0.0  50.0  31.0  12.0  18.0  24.0  48.0  43.0  44.0\n",
            "H376.VIII.52_S1C  33.0  1.0  25.0   7.0   1.0  21.0  17.0  41.0  22.0  18.0\n",
            "H376.IV.54_V1C    40.0  1.0  48.0  24.0  11.0   5.0   8.0  35.0  31.0  51.0\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 21s 1s/step - loss: 26.1554 - accuracy: 0.3723 - val_loss: 0.9585 - val_accuracy: 0.5690\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 22s 2s/step - loss: 0.8536 - accuracy: 0.6299 - val_loss: 0.5506 - val_accuracy: 0.8362\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.6711 - accuracy: 0.7143 - val_loss: 0.4725 - val_accuracy: 0.8621\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.6174 - accuracy: 0.7511 - val_loss: 0.4582 - val_accuracy: 0.8362\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.5503 - accuracy: 0.7771 - val_loss: 0.4904 - val_accuracy: 0.8103\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.5375 - accuracy: 0.7727 - val_loss: 0.3586 - val_accuracy: 0.8879\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 30s 2s/step - loss: 0.4361 - accuracy: 0.8290 - val_loss: 0.3511 - val_accuracy: 0.8793\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.4605 - accuracy: 0.8247 - val_loss: 0.3159 - val_accuracy: 0.8879\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.4562 - accuracy: 0.8333 - val_loss: 0.3194 - val_accuracy: 0.9310\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.3591 - accuracy: 0.8701 - val_loss: 0.1978 - val_accuracy: 0.9138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 278ms/step\n",
            "Class 0 ROC AUC: 1.00\n",
            "Class 1 ROC AUC: 1.00\n",
            "Class 2 ROC AUC: 0.99\n",
            "Class 3 ROC AUC: 0.99\n",
            "Macro-average ROC AUC: 0.99\n",
            "Images saved to baseline_cnn_classifier_outputs/rnaseq/CNN/train_images.png\n",
            "Columns after determining data type: Index(['hsa-miR-26a-5p', 'hsa-miR-181a-5p', 'hsa-miR-143-3p', 'hsa-let-7a-5p',\n",
            "       'hsa-miR-9-5p', 'hsa-miR-3182', 'hsa-miR-99b-5p', 'hsa-miR-30a-5p',\n",
            "       'hsa-miR-27b-3p', 'hsa-miR-191-5p',\n",
            "       ...\n",
            "       'hsa-miR-4653-5p', 'hsa-miR-4264', 'hsa-miR-3119', 'hsa-miR-4330',\n",
            "       'hsa-miR-4318', 'hsa-miR-4279', 'hsa-miR-3689f', 'hsa-miR-4291',\n",
            "       'donor_name', 'age'],\n",
            "      dtype='object', length=1863)\n",
            "Index(['hsa-miR-26a-5p', 'hsa-miR-181a-5p', 'hsa-miR-143-3p', 'hsa-let-7a-5p',\n",
            "       'hsa-miR-9-5p', 'hsa-miR-3182', 'hsa-miR-99b-5p', 'hsa-miR-30a-5p',\n",
            "       'hsa-miR-27b-3p', 'hsa-miR-191-5p',\n",
            "       ...\n",
            "       'hsa-miR-4653-5p', 'hsa-miR-4264', 'hsa-miR-3119', 'hsa-miR-4330',\n",
            "       'hsa-miR-4318', 'hsa-miR-4279', 'hsa-miR-3689f', 'hsa-miR-4291',\n",
            "       'donor_name', 'age'],\n",
            "      dtype='object', length=1863)\n",
            "[0 1 2 3]\n",
            "About to shuffle\n",
            "[0 1 2 3]\n",
            "                    hsa-miR-26a-5p  hsa-miR-181a-5p  hsa-miR-143-3p  \\\n",
            "H376_IX_52-MFC-L             219.0            188.0           208.0   \n",
            "H376_X_50_V1C-L              213.0            212.0           213.0   \n",
            "H376_XI_60_S1C-L             202.0            208.0           197.0   \n",
            "H376_VIII_54-HIP-L           197.0            187.0           173.0   \n",
            "H376_VIII_53_OFC-R           186.0            190.0           165.0   \n",
            "\n",
            "                    hsa-let-7a-5p  hsa-miR-9-5p  hsa-miR-3182  hsa-miR-99b-5p  \\\n",
            "H376_IX_52-MFC-L            204.0         194.0         148.0           171.0   \n",
            "H376_X_50_V1C-L             205.0         199.0         154.0           222.0   \n",
            "H376_XI_60_S1C-L            198.0         195.0         139.0           176.0   \n",
            "H376_VIII_54-HIP-L          186.0         184.0         176.0           170.0   \n",
            "H376_VIII_53_OFC-R          165.0         159.0         162.0           221.0   \n",
            "\n",
            "                    hsa-miR-30a-5p  hsa-miR-27b-3p  hsa-miR-191-5p  \n",
            "H376_IX_52-MFC-L             184.0           174.0           174.0  \n",
            "H376_X_50_V1C-L              190.0           190.0           183.0  \n",
            "H376_XI_60_S1C-L             188.0           193.0           178.0  \n",
            "H376_VIII_54-HIP-L           170.0           167.0           165.0  \n",
            "H376_VIII_53_OFC-R           153.0           150.0           175.0  \n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 10s 2s/step - loss: 4.4152 - accuracy: 0.2791 - val_loss: 1.3679 - val_accuracy: 0.3864\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.3374 - accuracy: 0.4535 - val_loss: 1.3044 - val_accuracy: 0.4773\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 9s 1s/step - loss: 1.3074 - accuracy: 0.4767 - val_loss: 1.2881 - val_accuracy: 0.4773\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.2886 - accuracy: 0.4826 - val_loss: 1.2650 - val_accuracy: 0.4773\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 10s 2s/step - loss: 1.2903 - accuracy: 0.4826 - val_loss: 1.2476 - val_accuracy: 0.4773\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.2658 - accuracy: 0.4767 - val_loss: 1.2736 - val_accuracy: 0.4773\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.2139 - accuracy: 0.4826 - val_loss: 1.2752 - val_accuracy: 0.4773\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.1425 - accuracy: 0.4884 - val_loss: 1.2033 - val_accuracy: 0.4773\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 9s 1s/step - loss: 1.0685 - accuracy: 0.4942 - val_loss: 1.4239 - val_accuracy: 0.4773\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.0574 - accuracy: 0.5814 - val_loss: 1.1229 - val_accuracy: 0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 140ms/step\n",
            "Class 0 ROC AUC: 0.56\n",
            "Class 1 ROC AUC: 0.74\n",
            "Class 2 ROC AUC: 0.85\n",
            "Class 3 ROC AUC: 0.87\n",
            "Macro-average ROC AUC: 0.76\n",
            "Images saved to baseline_cnn_classifier_outputs/microRNA/CNN/train_images.png\n"
          ]
        }
      ]
    }
  ]
}