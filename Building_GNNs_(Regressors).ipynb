{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VNiC19zsbsZ",
        "outputId": "3c22efec-fd21-438d-974b-851dec88b9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "print(joblib.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DS1fD2cs1Wn",
        "outputId": "aea5fc43-f421-4ca4-fd77-d0b530ee6e13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW9DKG4ns5UW",
        "outputId": "aea2d1ba-fcb2-4b7a-ddc2-8ab03c526ca3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_age_to_weeks(age_str):\n",
        "    if 'pcw' in age_str:\n",
        "        # Extract the number and use it directly\n",
        "        return float(age_str.split(' ')[0])\n",
        "    elif 'mos' in age_str:\n",
        "        # Convert months to weeks\n",
        "        return float(age_str.split(' ')[0]) * 4.345\n",
        "    elif 'yrs' in age_str or 'years' in age_str:\n",
        "        # Convert years to weeks\n",
        "        return float(age_str.split(' ')[0]) * 52\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown age format: {age_str}\")"
      ],
      "metadata": {
        "id": "9p3mKriys8zd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(X):\n",
        "    \"\"\"\n",
        "    Scales (standardizes) the input data.\n",
        "\n",
        "    Args:\n",
        "    - X (pd.DataFrame): Input data to be scaled.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: Scaled (standardized) data.\n",
        "    \"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "B9ntFJA3tD9b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graphs_from_correlations(X, threshold=0.8):\n",
        "    \"\"\"\n",
        "    Creates graphs based on correlation threshold.\n",
        "\n",
        "    Args:\n",
        "    - X (pd.DataFrame): Transposed DataFrame where each row is a gene and each column is a subject.\n",
        "    - threshold (float): Correlation threshold for edge creation.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of graph objects.\n",
        "    \"\"\"\n",
        "    # Calculate correlations\n",
        "    correlation_matrix = X.corr().abs()  # Using absolute value of correlations\n",
        "\n",
        "    print('Correlation matrix created')\n",
        "    # Initialize edge list\n",
        "    edge_list = []\n",
        "    for i in range(correlation_matrix.shape[0]):\n",
        "        for j in range(i + 1, correlation_matrix.shape[1]):\n",
        "            if correlation_matrix.iloc[i, j] >= threshold:\n",
        "                edge_list.append((i, j))\n",
        "    print('Edge list created')\n",
        "    # Convert edge list to tensor\n",
        "    edge_index_tensor = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "    print('Converted to tensor')\n",
        "    # Create graphs\n",
        "    graphs = []\n",
        "    for col in X.columns:\n",
        "        node_features = torch.tensor(X[col].values, dtype=torch.float).view(-1, 1)\n",
        "        graph = Data(x=node_features, edge_index=edge_index_tensor)\n",
        "        graphs.append(graph)\n",
        "    print('Graphs created')\n",
        "    return graphs"
      ],
      "metadata": {
        "id": "U7-fv4l8tNRG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data_path, file_type='csv'):\n",
        "    \"\"\"\n",
        "    Preprocess the data and return the train-test split.\n",
        "\n",
        "    Args:\n",
        "    - data_path (str): Path to the data file.\n",
        "    - file_type (str): File format ('csv', 'excel', 'txt').\n",
        "\n",
        "    Returns:\n",
        "    - X_train, X_test, y_train, y_test: Train-test split of the preprocessed data.\n",
        "    \"\"\"\n",
        "    subset_rows = 20\n",
        "\n",
        "\n",
        "    if 'methylation' in data_path.lower() and file_type == 'csv':\n",
        "        chunk_size = 5\n",
        "        chunks = pd.read_csv(data_path, chunksize=chunk_size)\n",
        "\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "        for chunk in chunks:\n",
        "            chunk = chunk.head(subset_rows)\n",
        "            X_chunk, y_chunk = preprocess_chunk(chunk, 'Methylation')\n",
        "\n",
        "            X_list.append(X_chunk)\n",
        "            y_list.append(y_chunk)\n",
        "\n",
        "        X_data = pd.concat(X_list, axis=0)\n",
        "        y_data = pd.concat(y_list, axis=0)\n",
        "\n",
        "        data = pd.concat([X_data, y_data], axis=1)\n",
        "        print(\"Columns after processing all chunks:\", data.columns)\n",
        "\n",
        "    else:\n",
        "        if file_type == 'csv':\n",
        "            data = pd.read_csv(data_path, index_col=0)\n",
        "        elif file_type == 'excel':\n",
        "            data = pd.read_excel(data_path, index_col=0)\n",
        "        elif file_type == 'txt':\n",
        "            data = pd.read_csv(data_path, sep='\\t', index_col=0)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file type\")\n",
        "        print(\"Columns after determining data type:\", data.columns)\n",
        "\n",
        "    if 'rnaseq' in data_path.lower():\n",
        "        data_type = 'RNA-Seq'\n",
        "    elif 'methylation' in data_path.lower():\n",
        "        data_type = 'Methylation'\n",
        "    elif 'microrna' in data_path.lower():\n",
        "        data_type = 'MicroRNA'\n",
        "    else:\n",
        "        raise ValueError(\"Unknown data type\")\n",
        "\n",
        "\n",
        "    # Reset the index of the DataFrame\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "    data['age'] = data['age'].apply(convert_age_to_weeks)\n",
        "\n",
        "    print(data.columns)\n",
        "\n",
        "    print(\"NaNs in age:\", data['age'].isna().sum())\n",
        "\n",
        "    if data_type == 'RNA-Seq':\n",
        "        data_numeric = data.drop(['age'], axis=1)\n",
        "        one_percent_of_samples = data_numeric.shape[1] * 0.01\n",
        "        mask = data_numeric.gt(1).sum(axis=1) >= one_percent_of_samples\n",
        "        filtered_data = data[mask]\n",
        "        # Extract y before transposing\n",
        "        y = torch.tensor(filtered_data['age'].values, dtype=torch.float)\n",
        "\n",
        "        # Transpose X to have genes as rows and subjects as columns\n",
        "        X = filtered_data.drop(['age'], axis=1).transpose()\n",
        "\n",
        "    elif data_type == 'Methylation':\n",
        "        relevant_columns = [col for col in data.columns if col.startswith(('cg', 'rs', 'ch'))] + ['age']\n",
        "        filtered_data = data[relevant_columns]\n",
        "        X = filtered_data.drop(['age'], axis=1).transpose()\n",
        "        print(X.head(5))\n",
        "        y = filtered_data['age']\n",
        "\n",
        "    elif data_type == 'MicroRNA':\n",
        "        relevant_columns = [col for col in data.columns if col.startswith('hsa')] + ['age']\n",
        "        filtered_data = data[relevant_columns]\n",
        "        # Extract y before transposing\n",
        "        y = torch.tensor(filtered_data['age'].values, dtype=torch.float)\n",
        "\n",
        "        # Transpose X to have genes as rows and subjects as columns\n",
        "        X = filtered_data.drop(['age'], axis=1).transpose()\n",
        "\n",
        "\n",
        "    print(np.unique(y))\n",
        "    # print(\"About to shuffle\")\n",
        "    print(\"X shape:\", X.shape)\n",
        "    print(\"y shape:\", y.shape)\n",
        "\n",
        "    # X, y = shuffle(X, y, random_state=0)\n",
        "    X_scaled = scale(X)\n",
        "\n",
        "    # Convert the scaled data back to a DataFrame\n",
        "    X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
        "\n",
        "    # Create graphs directly from scaled X (which is now a numpy array)\n",
        "    graphs = create_graphs_from_correlations(pd.DataFrame(X_scaled, index=X.index), threshold=0.8)\n",
        "\n",
        "    graphs_train, graphs_test, y_train, y_test = train_test_split(graphs, y, test_size=0.2, random_state=42)\n",
        "    print(\"The data is split\")\n",
        "\n",
        "    return graphs_train, graphs_test, y_train, y_test"
      ],
      "metadata": {
        "id": "eNxX6vfutNvI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data_splits(X_train, X_test, y_train, y_test, output_dir):\n",
        "    \"\"\"\n",
        "    Saves the train-test data splits to the specified directory using joblib.\n",
        "\n",
        "    Args:\n",
        "    - X_train (pd.DataFrame or np.ndarray): Training data features.\n",
        "    - X_test (pd.DataFrame or np.ndarray): Testing data features.\n",
        "    - y_train (pd.Series or np.ndarray): Training data labels.\n",
        "    - y_test (pd.Series or np.ndarray): Testing data labels.\n",
        "    - output_dir (str): Directory path where the data splits will be saved.\n",
        "\n",
        "    Note:\n",
        "    - If the output directory does not exist, it will be created.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    joblib.dump(X_train, os.path.join(output_dir, 'X_train_regressors.pkl'))\n",
        "    joblib.dump(X_test, os.path.join(output_dir, 'X_test_regressors.pkl'))\n",
        "    joblib.dump(y_train, os.path.join(output_dir, 'y_train_regressors.pkl'))\n",
        "    joblib.dump(y_test, os.path.join(output_dir, 'y_test_regressors.pkl'))"
      ],
      "metadata": {
        "id": "0TkBFkMVtYTQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "def train_evaluate_regressor(regressor, X_train, y_train, X_test, y_test, output_dir):\n",
        "    \"\"\"\n",
        "    Trains the regressor on the training data, evaluates it on the test data,\n",
        "    and saves the trained model and performance metrics to the specified directory.\n",
        "    \"\"\"\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"R-squared: {r2}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    with open(os.path.join(output_dir, 'performance_metrics.txt'), 'w') as f:\n",
        "        f.write(f\"Mean Squared Error: {mse}\\n\")\n",
        "        f.write(f\"R-squared: {r2}\\n\")\n",
        "\n",
        "    joblib.dump(regressor, os.path.join(output_dir, 'trained_model.pkl'))\n",
        "\n",
        "    return y_pred, regressor"
      ],
      "metadata": {
        "id": "g7O3mnHqty2o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(graphs, ages, batch_size=32):\n",
        "    graph_data_list = []\n",
        "    for i, graph in enumerate(graphs):\n",
        "        age_label = torch.tensor([ages[i]], dtype=torch.float)\n",
        "        graph_data_list.append(Data(x=graph.x, edge_index=graph.edge_index, y=age_label))\n",
        "\n",
        "    return DataLoader(graph_data_list, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "jWQDrgaJt04p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_gat_model(train_loader, test_loader, epochs=100):\n",
        "    \"\"\"\n",
        "    Trains and evaluates a GAT model.\n",
        "\n",
        "    Args:\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - num_classes (int): Number of classes for classification.\n",
        "    - epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "    - model: Trained GAT model.\n",
        "    - avg_test_loss: Average loss on the test set.\n",
        "    - test_accuracy: Accuracy on the test set.\n",
        "    \"\"\"\n",
        "    class GATNetRegressor(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(GATNetRegressor, self).__init__()\n",
        "          self.conv1 = GATConv(1, 8, heads=8, dropout=0.6)  # Accepts 1 feature per node\n",
        "          self.conv2 = GATConv(8 * 8, 16, heads=1, dropout=0.6)\n",
        "          self.fc = torch.nn.Linear(16, 1)  # Output layer for regression\n",
        "\n",
        "      def forward(self, data):\n",
        "          x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "          x = F.dropout(x, p=0.6, training=self.training)\n",
        "          x = F.elu(self.conv1(x, edge_index))\n",
        "          x = F.dropout(x, p=0.6, training=self.training)\n",
        "          x = F.elu(self.conv2(x, edge_index))\n",
        "\n",
        "          x = global_mean_pool(x, batch)  # Pooling to get graph-level representation\n",
        "          x = self.fc(x)\n",
        "          return x  # No softmax for regression\n",
        "\n",
        "\n",
        "    model = GATNetRegressor()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch)\n",
        "            loss = criterion(output.view(-1), batch.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        output = model(batch)\n",
        "        loss = criterion(output, batch.y.long())\n",
        "        total_test_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += batch.y.size(0)\n",
        "        correct += (predicted == batch.y.long()).sum().item()\n",
        "\n",
        "    avg_test_loss = total_test_loss / len(test_loader)\n",
        "    test_accuracy = 100 * correct / total\n",
        "\n",
        "\n",
        "\n",
        "    return model, avg_test_loss"
      ],
      "metadata": {
        "id": "aCVsigqdt3XZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(data_paths):\n",
        "\n",
        "    for data_path in data_paths:\n",
        "\n",
        "        data_type = os.path.basename(data_path).split('_')[0]\n",
        "\n",
        "        graphs_train, graphs_test, y_train, y_test = preprocess_data(data_path)\n",
        "        save_data_splits(graphs_train, graphs_test, y_train, y_test, os.path.join('baseline_cnn_outputs', data_type))\n",
        "\n",
        "        train_loader = create_data_loader(graphs_train, y_train)\n",
        "        print('Train loader created')\n",
        "        test_loader = create_data_loader(graphs_test, y_test)\n",
        "        print('Test loader created')\n",
        "\n",
        "        model, avg_test_loss = train_evaluate_gat_model(train_loader, test_loader, epochs=10)\n",
        "\n",
        "        print(f\"GAT Model - Test Loss: {avg_test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "ebBOV6Xkt6R_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_paths = [#'methylation_1.csv',\n",
        "              '/content/drive/MyDrive/rnaseq/rnaseq_1.csv',\n",
        "              '/content/drive/MyDrive/microRNA/microRNA_1.csv'\n",
        "              ]\n",
        "main(data_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW_gY2Fkt-li",
        "outputId": "7bc7e7db-eaac-4c0e-c02f-e341db8cabc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns after determining data type: Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
            "       ...\n",
            "       '22319', '22320', '22321', '22322', '22323', '22324', '22325', '22326',\n",
            "       '22327', 'age'],\n",
            "      dtype='object', length=22328)\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
            "       ...\n",
            "       '22319', '22320', '22321', '22322', '22323', '22324', '22325', '22326',\n",
            "       '22327', 'age'],\n",
            "      dtype='object', length=22328)\n",
            "NaNs in age: 0\n",
            "[   8.      9.     12.     13.     16.     17.     17.38   19.     21.\n",
            "   24.     25.     26.     26.07   43.45   52.    104.    156.    208.\n",
            "  416.    572.    676.    780.    936.    988.   1092.   1196.   1560.\n",
            " 1872.   1924.   2080.  ]\n",
            "X shape: (22327, 578)\n",
            "y shape: torch.Size([578])\n",
            "Correlation matrix created\n",
            "Edge list created\n",
            "Converted to tensor\n",
            "Graphs created\n",
            "The data is split\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader created\n",
            "Test loader created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT Model - Test Loss: 450941.7891\n",
            "Columns after determining data type: Index(['hsa-miR-26a-5p', 'hsa-miR-181a-5p', 'hsa-miR-143-3p', 'hsa-let-7a-5p',\n",
            "       'hsa-miR-9-5p', 'hsa-miR-3182', 'hsa-miR-99b-5p', 'hsa-miR-30a-5p',\n",
            "       'hsa-miR-27b-3p', 'hsa-miR-191-5p',\n",
            "       ...\n",
            "       'hsa-miR-4653-5p', 'hsa-miR-4264', 'hsa-miR-3119', 'hsa-miR-4330',\n",
            "       'hsa-miR-4318', 'hsa-miR-4279', 'hsa-miR-3689f', 'hsa-miR-4291',\n",
            "       'donor_name', 'age'],\n",
            "      dtype='object', length=1863)\n",
            "Index(['hsa-miR-26a-5p', 'hsa-miR-181a-5p', 'hsa-miR-143-3p', 'hsa-let-7a-5p',\n",
            "       'hsa-miR-9-5p', 'hsa-miR-3182', 'hsa-miR-99b-5p', 'hsa-miR-30a-5p',\n",
            "       'hsa-miR-27b-3p', 'hsa-miR-191-5p',\n",
            "       ...\n",
            "       'hsa-miR-4653-5p', 'hsa-miR-4264', 'hsa-miR-3119', 'hsa-miR-4330',\n",
            "       'hsa-miR-4318', 'hsa-miR-4279', 'hsa-miR-3689f', 'hsa-miR-4291',\n",
            "       'donor_name', 'age'],\n",
            "      dtype='object', length=1863)\n",
            "NaNs in age: 0\n",
            "[  17.38   26.07   43.45   52.    104.    156.    208.    416.    572.\n",
            "  676.    780.    936.    988.   1092.   1196.  ]\n",
            "X shape: (1861, 216)\n",
            "y shape: torch.Size([216])\n",
            "Correlation matrix created\n",
            "Edge list created\n",
            "Converted to tensor\n",
            "Graphs created\n",
            "The data is split\n",
            "Train loader created\n",
            "Test loader created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT Model - Test Loss: 272288.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    }
  ]
}